

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Using LSTM model &mdash; MIL WebDNN 1.2.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="MIL WebDNN 1.2.1 documentation" href="../index.html"/>
        <link rel="up" title="Tips" href="index.html"/>
        <link rel="next" title="EcmaScript5 support" href="es5.html"/>
        <link rel="prev" title="Building webdnn.js" href="build_js.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> MIL WebDNN
          

          
          </a>

          
            
            
              <div class="version">
                1.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../tutorial/index.html">Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tips</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="enable_webgpu_ios.html">Enabling WebGPU on iOS 11</a></li>
<li class="toctree-l2"><a class="reference internal" href="enable_webgpu_macos.html">Enabling WebGPU on macOS 10.13 High Sierra</a></li>
<li class="toctree-l2"><a class="reference internal" href="build_js.html">Building webdnn.js</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Using LSTM model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sequence-input-final-state-output">Sequence input, final state output</a></li>
<li class="toctree-l3"><a class="reference internal" href="#iterative-sequence-generation">Iterative sequence generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#more-advanced-example">More advanced example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="es5.html">EcmaScript5 support</a></li>
<li class="toctree-l2"><a class="reference internal" href="safari_webcam.html">Using web camera in Safari</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_reference/graph_transpiler/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_reference/descriptor-runner/index.html">JavaScript API</a></li>
</ul>
<p class="caption"><span class="caption-text">Contributing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contributing/index.html">How to Contribute</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MIL WebDNN</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Tips</a> &raquo;</li>
        
      <li>Using LSTM model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/tips/lstm.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="using-lstm-model">
<span id="using-lstm-model"></span><h1>Using LSTM model<a class="headerlink" href="#using-lstm-model" title="Permalink to this headline">¶</a></h1>
<p>LSTM is a DNN layer which accepts sequence and update internal state according to it. LSTM is widely used for natual lauguage analysis and generation. If you are new to LSTM itself, refer to <a class="reference external" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">articles</a> of sequential models.</p>
<p>From WebDNN 1.1.0, LSTM layer is supported. As of WebDNN 1.1.0, automatic model conversion is supported only from Keras. Compared to image classification model, using LSTM-based model requires more implementation in JavaScript side. This document describes some common use-cases of LSTM.</p>
<div class="section" id="sequence-input-final-state-output">
<span id="sequence-input-final-state-output"></span><h2>Sequence input, final state output<a class="headerlink" href="#sequence-input-final-state-output" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal"><span class="pre">example/lstm</span></code> illustrates the most simple usage of LSTM model. The model accepts sequence of words in sentences, and outputs its sentiment as a scalar value (vector with only 1 elements).</p>
<p>The simplest model definition is as follows.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">max_features</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>Also, you can stack LSTM for higher model accuracy. First LSTM layer now outputs sequence of states, not only last state. But this modification does not affect input/output format of the whole model.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">max_features</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>  <span class="c1"># stacked lstm</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>Usage of this model in descriptor runner is the same as image classification CNN model.</p>
<div class="highlight-javascript"><div class="highlight"><pre><span></span><span class="nx">runner</span><span class="p">.</span><span class="nx">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">set</span><span class="p">(</span><span class="nx">input_sequence</span><span class="p">);</span>
<span class="nx">await</span> <span class="nx">runner</span><span class="p">.</span><span class="nx">run</span><span class="p">();</span>
<span class="kd">let</span> <span class="nx">prediction_vector</span> <span class="o">=</span> <span class="nx">runner</span><span class="p">.</span><span class="nx">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">toActual</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="section" id="iterative-sequence-generation">
<span id="iterative-sequence-generation"></span><h2>Iterative sequence generation<a class="headerlink" href="#iterative-sequence-generation" title="Permalink to this headline">¶</a></h2>
<p>Natural language generation models generally requires iterative execution of LSTM model with sampling.</p>
<p>One kind of such models accept last N characters (or words) of the sentence and predicts probability of next character (or word). Then, concrete character is selected according to the probability (select character with highest probability or randomly sampling with predicted probability). This selection is called as sampling. Then, selected character is concatenated to the sentence. By iteratively executing such procedures, long sentences are generated.</p>
<p><code class="docutils literal"><span class="pre">example/text_generation</span></code> is the example of sentence generation using the procedure mentioned above. The model definition is follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">))))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>The model accepts last <code class="docutils literal"><span class="pre">maxlen</span></code> characters of the sentence, and outputs next character&#8217;s probability. WebDNN itself does not support character sampling, so it have to be implemented in JavaScript. By feeding updated sentence to descriptor runner iteratively, a sentence is generated.</p>
<div class="highlight-javascript"><div class="highlight"><pre><span></span><span class="kd">let</span> <span class="nx">sentence</span> <span class="o">=</span> <span class="nx">sentence_seed</span><span class="p">;</span>

<span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// input current sentence to the model</span>
    <span class="nx">runner</span><span class="p">.</span><span class="nx">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">set</span><span class="p">(</span><span class="nx">sentence_to_array</span><span class="p">(</span><span class="nx">sentence</span><span class="p">));</span>

    <span class="c1">// predict next character&#39;s probability</span>
    <span class="nx">await</span> <span class="nx">runner</span><span class="p">.</span><span class="nx">run</span><span class="p">();</span>
    <span class="kd">let</span> <span class="nx">out_vec</span> <span class="o">=</span> <span class="nx">runner</span><span class="p">.</span><span class="nx">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">toActual</span><span class="p">();</span>
    <span class="c1">// sample next character</span>
    <span class="kd">let</span> <span class="nx">next_char</span> <span class="o">=</span> <span class="nx">sample_next_char</span><span class="p">(</span><span class="nx">out_vec</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">);</span>
    <span class="nx">sentence</span> <span class="o">+=</span> <span class="nx">next_char</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Function <code class="docutils literal"><span class="pre">sentence_to_array</span></code> generates sequence of one-hot-vector of last <code class="docutils literal"><span class="pre">maxlen</span></code> characters. Function <code class="docutils literal"><span class="pre">sample_next_char</span></code> samples concrete character from probability vector from the model.</p>
</div>
<div class="section" id="more-advanced-example">
<span id="more-advanced-example"></span><h2>More advanced example<a class="headerlink" href="#more-advanced-example" title="Permalink to this headline">¶</a></h2>
<p>One of the more advanced examples is image captioning. Image captioning is an application that generate natural language sentence which describes given image.</p>
<p><a class="reference external" href="https://github.com/milhidaka/chainer-image-caption">https://github.com/milhidaka/chainer-image-caption</a></p>
<p>In this example, the following techniques are used:</p>
<ul class="simple">
<li>Converting Chainer model manually into WebDNN IR</li>
<li>Using multiple descriptor runner (image feature extraction and sentence generation)</li>
<li>Switching two inputs in sentence generation<ul>
<li>LSTM requires image feature for first iteration, then requires sampled character</li>
</ul>
</li>
</ul>
<p>This example is a reference for using complex model in WebDNN.</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="es5.html" class="btn btn-neutral float-right" title="EcmaScript5 support" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="build_js.html" class="btn btn-neutral" title="Building webdnn.js" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, MIL.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.2.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>